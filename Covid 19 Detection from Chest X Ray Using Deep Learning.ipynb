{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import cv2                 \n",
    "import numpy as np         \n",
    "import os                  \n",
    "from random import shuffle\n",
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import glob as gb\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read DataSet\n",
    "TrianImage=\"/kaggle/input/chest-xray-covid19-pneumonia/Data/train/\"\n",
    "TestImage=\"/kaggle/input/chest-xray-covid19-pneumonia/Data/test/\"\n",
    "\n",
    "\n",
    "print(TrianImage)\n",
    "print(TestImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to get all image names in train file\n",
    "Pneumonaimages = os.listdir(TrianImage + \"/PNEUMONIA\")\n",
    "Normalimages = os.listdir(TrianImage + \"/NORMAL\")\n",
    "COVID19images = os.listdir(TrianImage + \"/COVID19\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # **Explore the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot to show the size of some image\n",
    "#plot PNEUMONIA\n",
    "plt.figure(figsize=(20,10))\n",
    "for i in range(6):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(plt.imread(os.path.join(TrianImage + \"/PNEUMONIA\",Pneumonaimages[i])),cmap='gray')\n",
    "    plt.title(\"PNEUMONIA\")\n",
    "    \n",
    "plt.show()\n",
    "#plot NORMAL\n",
    "plt.figure(figsize=(20,10))\n",
    "for i in range(6):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(plt.imread(os.path.join(TrianImage + \"/NORMAL\",Normalimages[i])),cmap='gray')\n",
    "    plt.title(\"NORMAL\")\n",
    "\n",
    "plt.show()\n",
    "#plot \n",
    "plt.figure(figsize=(20,10))\n",
    "for i in range(6):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(plt.imread(os.path.join(TrianImage + \"/COVID19\",COVID19images[i])),cmap='gray')\n",
    "    plt.title(\"COVID19\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageDataGenerator (DataAugmentation )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also use the generator to transform the values in each batch so that their mean is $0$ and their standard deviation is 1.\n",
    "This will facilitate model training by standardizing the input distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generator also converts our single channel X-ray images (gray-scale) to a three-channel format by repeating the values in the image across all channels.\n",
    "We will want this because the pre-trained model that we'll use requires three-channel inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "      samplewise_center=True,\n",
    "      samplewise_std_normalization= True,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      fill_mode='nearest'\n",
    "                                  )\n",
    "\n",
    "# NOTE: YOU MUST USE A BATCH SIZE OF 10 (batch_size=10) FOR THE \n",
    "# TRAIN GENERATOR.\n",
    "train_generator =train_datagen.flow_from_directory(\n",
    "     TrianImage,\n",
    "     batch_size= 256,\n",
    "     shuffle=shuffle,\n",
    "     target_size=(300, 300)\n",
    "\n",
    ")\n",
    "\n",
    "test_generator =train_datagen.flow_from_directory(\n",
    "     TestImage,\n",
    "     batch_size= 50,\n",
    "     shuffle=shuffle,\n",
    "     target_size=(300, 300)\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainShape=train_generator.__getitem__(0)[0].shape\n",
    "testShape=test_generator.__getitem__(0)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shape of Data\n",
    "print(\"Train Shape \\n\",trainShape)\n",
    "print(\"Test Shape \\n\",testShape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Labels={'NORMAL':0,'PNEUMONIA':1,'COVID19':2}\n",
    "\n",
    "# convert label to code\n",
    "def getCode(label):\n",
    "    return Labels[label]\n",
    "\n",
    "\n",
    "# convert code to label \n",
    "def getLabel(n):\n",
    "    for x,c in Labels.items():\n",
    "        if n==c:\n",
    "            return x\n",
    "        \n",
    "        \n",
    "        \n",
    "#Test        \n",
    "print(getCode('COVID19'))\n",
    "print(getLabel(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Data After DataAugmentation and standardizing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(train_generator.__getitem__(0)[0][i])\n",
    "    plt.title(getLabel(np.argmax(train_generator.__getitem__(0)[1][i])) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another Way To Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading image data\n",
    "import glob as gb\n",
    "import cv2  \n",
    "sizeImage=300 # to resize the all image as same size\n",
    "\n",
    "#to read all images from directory\n",
    "def getData(Dir,sizeImage):\n",
    "    X=[]\n",
    "    y=[]\n",
    "    for folder in  os.listdir(Dir) : #to get the file name \n",
    "        files = gb.glob(pathname= str( Dir  +\"/\" +folder+ '//*.jpg' )) # to get the images\n",
    "        for file in files:\n",
    "                picture=cv2.imread(file) #  or plt.imread(file)\n",
    "                imageArray=cv2.resize(picture,(sizeImage,sizeImage))\n",
    "                X.append(list(imageArray))\n",
    "                y.append(getCode(folder))\n",
    "    X=np.array(X)\n",
    "    y=np.array(y)\n",
    "    return X,y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get train data\n",
    "X_train, y_train = getData(TrianImage,sizeImage)\n",
    "# get test data\n",
    "X_test , y_test = getData(TestImage,sizeImage)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train Shape        \",X_train.shape)\n",
    "print(\"X_test Shape         \",X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Convert y_train to categorical\n",
    "y_train=to_categorical(y_train,3)\n",
    "print(\"y_train \",y_train.shape)\n",
    "\n",
    "\n",
    "\n",
    "#Convert y_train to categorical\n",
    "y_test=to_categorical(y_test,3)\n",
    "print(\"y_test \",y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load weight\n",
    "Network_Weight=\"/kaggle/input/densenet-keras/DenseNet-BC-169-32-no-top.h5\"\n",
    "print(Network_Weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizeImage=300 \n",
    "from tensorflow.keras.applications.densenet import DenseNet169\n",
    "pre_trained_model = DenseNet169(input_shape = (sizeImage, sizeImage, 3), \n",
    "                                include_top = False, \n",
    "                                weights = None)\n",
    "pre_trained_model.load_weights(Network_Weight)\n",
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainable = False  #to make the layers to Freeze Weights\n",
    "pre_trained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "x = tf.keras.layers.Flatten()(pre_trained_model.output)\n",
    "\n",
    "#Full Connected Layers\n",
    "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "#Add dropout to avoid Overfit\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "#Add dropout to avoid Overfit\n",
    "x = tf.keras.layers.Dropout(0.4)(x)\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "\n",
    "\n",
    "x=tf.keras.layers.Dense(3 , activation='sigmoid')(x)\n",
    "       \n",
    "\n",
    "model = Model( pre_trained_model.input, x) \n",
    "\n",
    "print(model.summary())\n",
    "model.compile(optimizer='adam', loss=\"binary_crossentropy\",metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau , ModelCheckpoint\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.1, epsilon=0.0001, patience=1, verbose=1)\n",
    "\n",
    "filepath=\"transferlearning_weights.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "history = model.fit_generator(train_generator,steps_per_epoch=20,callbacks=[lr_reduce,checkpoint] ,\n",
    "         epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate Model\n",
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('modelCovid19___2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction\n",
    "pred=model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=[]\n",
    "for i in range(26):\n",
    "    y_test.extend(test_generator.__getitem__(i)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y_test))\n",
    "y_test=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=np.argmax(y_test,axis=1)\n",
    "pred= np.argmax(pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"pred \\n\",len(pred))\n",
    "print(\"y_test \\n\",len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"y_test \\n\",y_test)\n",
    "print(\"pred \\n\",pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion_matrix to check in accuracy \n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(pred,y_test)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "for i in range(0,9):\n",
    "    \n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    \n",
    "    plt.imshow(test_generator.__getitem__(0)[0][i],cmap='gray')\n",
    "    plt.title(f\"   Real: {getLabel(y_test[i])   } Vs  Predict: {getLabel(pred[i])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lto load model\n",
    "from keras.models import load_model\n",
    "loadedModel=load_model(\"modelCovid19___2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadedModel.compile(optimizer='adam', loss=\"binary_crossentropy\",metrics=['accuracy'])\n",
    "loadedModel.evaluate(test_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
